\documentclass[10pt,a4paper]{article}
\usepackage[ansinew]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
%\usepackage{natbib}
\usepackage[natbibapa]{apacite}
\usepackage{linguex}
%\usepackage[german]{babel}
\usepackage{listings}
\usepackage{color}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
	{-2.5ex\@plus -1ex \@minus -.25ex}%
	{1.25ex \@plus .25ex}%
	{\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{4} % how many sectioning levels to assign numbers to
\setcounter{tocdepth}{4}    % how many sectioning levels to show in ToC

\makeatletter
\renewcommand\subparagraph{\@startsection{subparagraph}{5}{\z@}%
	{-2.5ex\@plus -1ex \@minus -.25ex}%
	{1.25ex \@plus .25ex}%
	{\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{5} % how many sectioning levels to assign numbers to
\setcounter{tocdepth}{5}    % how many sectioning levels to show in ToC


\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
	language=Java,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}


\begin{document}
		\title{Sex as a factor in the processing of visually and socially situated language in younger adults.\\An eye tracking study.}
		\author{Maria Antonietta Osso\\Matr.-Nr.: 555955\\maria.antonietta.osso@gmail.com\\Humboldt-Universität zu Berlin\\}
		\maketitle
	
	
	\begin{abstract}
		Characteristics of the listener such as age have been found to have an impact on the time course of language processing in the visual and social context. Does the sex of the listener have an impact on language processing, too? In my master's thesis, I will follow up on research about the role of listener's characteristics in situated language comprehension \citep{muen} and propose a design in which I will control for age and test for sex differences in language processing. Based on the data collected until the time of writing this thesis, ------------
	\end{abstract}
	\section{Introduction}
	In the last decade, a growing body of research has been investigating the relation between language processing and the broader non-linguistic context in which language is embedded. Visual and social situational information have been found to have an impact in the time course of language processing; visual and social cues are also used by listener-viewers to disambiguate among possible options in visually situated thematic role assignment \citep{muen, kno15, cakn}. Crucially, the effect of the visual and social context seems to be modulated by selected characteristics of the listener-viewer, like age \citep{zhkno, muen} and literacy \citep{mish}. May the sex of the listener-viewer (a characteristic which has been found to play a role in other areas of cognition \citep{li, cahi, moss}) also be a factor in situated language processing?\\
	
	This study investigates the effect of social cues on online language comprehension. Specifically, it investigates the effect of emotionally valenced facial expression of the speaker on real-time thematic role assignment in emotionally valenced non-canonical sentences, and how this effect might be modulated by the sex of the listener-viewer.\\
	
	A remark on the terminology: The phrase \textit{sex of the comprehender} may have different interpretations. \textit{Sex} may be understood as the biological sex, or as the gender identity of a person. In this thesis, I will refer to \textit{sex} as biological sex - as opposed to \textit{gender}, which I understand as sexual identity.\\
	
	In this master's thesis, I will first briefly review the relevant literature (Sections 2 and 3), then present the experiment materials and procedure (Section 4) and introduce my hypotheses (Section 5). Section 6 is dedicated to data collection, data analysis and to the presentation of the results. A general discussion of the results will follow (Section 7) and, finally, a short summary (Section 8).\\ 
	\section{Visual and social cues and sentence processing}
	Visual cues may change the time course of incremental sentence processing and help skilled listeners in disambiguating between plausible semantic meanings and concurrent syntactic structures. Eye-tracking studies show that congruent visual stimuli facilitate anticipatory saccades toward a yet-to-be-named visual target, thus showing that disambiguation happens based on the integration of the visual material into incremental sentence processing \citep{kno15}.\\
	
	The visual world facilitates anticipatory eye movements toward a target image in eye-tracking experiments \citep{ande, zhkno}. Visual cues have also been found to interact with language processing in an ERP name-picture matching experiment in which participants visually inspected pictures while the depicted referent or a distractor word was named. An N400 effect was observed between the congruent name-picture condition and the incongruent condition, thus pointing to the existence of an interaction between the visual stimuli and the linguistic material at a level of semantic priming \citep{frie}.
	
	Depicted emotional primes have also been found to facilitate anticipatory looks to an emotionally congruent target \citep{cakn, muen}, suggesting that, just like visual cues, social cues seem to be integrated in language processing and to be able to elicit priming effects. \cite{muen}, with a study which embeds sentences in the social context through visual presentation of emotionally valenced facial expressions, found that viewer-listeners are able to correctly assign a thematic role to a yet-to-be-named agent using social information. Her participants were presented OVS sentences paired with visual scenes. The visual scenes portrayed the sentence's agent and patient as well as a distractor and the action described in the scene. The sentences contained an emotionally valenced (positive or negative) adverb which referred to the agent internal state while performing the action, and the figures in the scenes had a marked positive or negative facial expression. Based on this information, participants were able to identify which of the possible figures fulfilled the agent role before the agent was named. Additionally, participants were primed for a positive or negative emotion before seeing each scene. The anticipatory effect of the adverb-picture emotion matching was stronger when the primed emotion was congruent with the emotion expressed in the sentence.\\
	
	\section{Characteristics of the listener and sentence processing}
	Differences in the socially mediated thematic role assignment in the visual are modulated by the age of the listener. While younger adults do use and integrate social information into incremental sentence comprehension, older adults show a preference for positive emotions and young children do not seem to use this information \citep{muen}. As a listerner's characteristic which is found to have impact in other areas of cognition \citep{li}, gender may play a role in online language processing in the social context, too.\\
	
	A recent study by \cite{aden} confirmed the existence of sex-related differences between males and females in Theory of Mind based on two different tasks, a Reading the Mind in the Eyes (RME) tasks and an Attribution of Intention (AI) task. In the RME study, participants are asked to identify what a person is thinking of or feeling based on a picture of his/her eyes only. A high RME score corresponds to high abilities in identifying the state of mind of others based on visual cues. In the AI study, the same participants were asked to chose an appropriate ending to a short videoclip. High scores in this task are linked to high abilities in inferring the intention of others based on visual cues. In both experiments, a transcranial direct-current stumulation (tDCS) condition (in which the area of the brain engaged in ToM tasks was stimulated) was compared with a placebo condition (in which no stimulation occurred). The stimulation was able to enhance ToM performances in women, but not in men. A possible explanation for this difference is that men and women make use of ToM at a different extent when making inferences about the state of mind or the intentions of others.\\
	
	The evidence mentioned above is compatible with the empathizing-systemyzing (E-S) framework according to which a typical female brain more heavily relies on Theory of Mind than a typical male brain does \citep{baro}. Doing so, women prefer to extract information and elaborate predictions based on inferences about the state of mind or the intentions of others. On the other hand, men prefer to focus on how systems work, and to base their predictions on the rules they can generalize from what they observe in those systems.	The E-S theory of psychological sex differences does not assume that every woman will have a typical female brain nor that every man will have a typical male brain, but it does predict that, in a healthy population, this will be true in average \citep{baro}.\\
	
	It seems plausible to assume that differences in the identification and use of internal states of others may lead to differences in the time course of language processing in the social context.\\
	
	\section{Procedure}
	64 young adults between 18 and 30 will be listening to a set of sentences, each of which describes a cartoon-like scene showed on a computer monitor. Using an EyeLink 1000 eye-tracker, I will record their eye-movements and analyze their fixation patterns to determine the time course of attention shift.\\
	
	The duration of one trial is approximately 20 to 25 seconds, which multiplied by 48 trials sums up to a maximum of 20 minutes per participant. Time for eventual clarifications during the practice trials, participant's pauses and formal fulfillments needs to be added to the count, for a total expected duration of 30 to 45 minutes per participant.\\
	
	\subsection{Design and materials}
	In a 1 factor x 2 levels between-groups design, I will verify whether thematic role assignment in a visual context may be facilitated by emotional priming and whether this is affected by the sex of the listener. Procedure and stimuli are adapted from \citet{muen}, experiment 3.\\
	
	%LISTS
	
	The dataset consists of 8 lists of 48 trials each. They all start with 4 practice trials and then contain the same 16 item trials and 28 fillers. Trials are counterbalanced across lists for position of the target (for each item, the actor appears on the right hand side in 50\% of the lists, or on the left hand side in the remaining 50\% of the lists). They were also counterbalanced for valence of the prime video (a same item was paired with a negative prime face in 50\% of the lists, and with a positive prime face in the other 50\% of the lists). The position of the response keys is switched after 50\% of the subjects are tested (the labels and values of the yes/no buttons are inverted for the second half of the participants, so that 32 participants will answer "yes" using their right index finger, while the remaining 32 participants will do so using their left index finger).\\
	
	In the verification tasks, the expected participant's responses are counterbalanced within each list. Trial and verification sentences will have the same meaning in half of the trials and prime and verification face will be congruent in half of the trials, so that 22 "yes" and 22 "no" answers are expected in both tasks. Item trials are always verified with "yes" in the sentence verification task.\\
	
	The dataset was created in Excel and specified as master list in the Experiment Builder. The single data sources for each individual participant, instead, are .txt files containing only one list at a time. The 8 original lists were randomized 8 times each using following MIX script\footnote{See \cite{cada} for the MIX documentation}:
	
	\begin{lstlisting}
		// sets the path of one original list 1; the list has to be a saved as a comma separated vector
		ItemFile [path_original_list_1.csv]
		// originates 8 different randomizations of list 1 and saves them as text files under the specified path
		OutputFile [path_randomization1.txt]
		OutputFile [path_randomization2.txt]
		OutputFile [path_randomization3.txt]
		OutputFile [path_randomization4.txt]
		OutputFile [path_randomization5.txt]
		OutputFile [path_randomization6.txt]
		OutputFile [path_randomization7.txt]
		OutputFile [path_randomization8.txt]
		
		// up until now, any randomization would be allowed. This includes, for example, sequences of several items and/or several fillers. Our goal is to create sequences of one item and two fillers only. Therefore, I set constraints to the allowed sequences of lines.
		
    		// labels the fourth element of all strings as "type" (MIX finds the fourth element as indexed under "3", as it uses zero-based indexing - i.e. the first element is element 0)
	    	Property type 3
		
		    // constraint 1: sets that any "type" element may not be repeated more than two times in a row. This will make sure that not more than two fillers or two items will follow one another in any randomization
		    Constraint type MaxRep 2
		
		    // constraint 2: sets that "1" may not appear more than one time in a row. This constraint will ensure that no two items will follow one onother in any of the randomized lists. Together with contraint 1, it ensures that only sequences of two fillers and one item are possible.
		    Constraint type MaxRep 1 1
		
		    // labels the sixteenth element of each string as "valence"
		    Property valence 15
		
		    // constraint 3: sets that any "valence" element may not be repeated more than two times in a row
		    Constraint valence MaxRep 2
		
		// we now have the right sequence. I further need to establish that the first and last trial will always be a filler, as well as make sure that the headers will remain at the top of the table. For MIX, the header are not different than any row containing values, so that it would be randomized as such if I do not explicitly state otherwise.
		
		    // labels as "startitem" the string with filler_1.jpg as eighteenth element
		    LineType startitem 17 filler_1.jpg
		
		    // labels as "enditem" the string with filler_28.jpg as eighteenth element
		    LineType enditem 17 filler_28.jpg
		
		    // labels as "head" the string with list as second element
		    LineType head 1 list
		
		    // constraint 4: fixates the position of "startitem", "enditem" and "head" so that these trials will be excluded from the randomization and will occupy in the randomized lists the same position they occupied in the original list
	    	FixType startitem enditem head
		
	\end{lstlisting}
	
	After the pseudorandomization with MIX, the lists will be ready to use without any further manual adjustments. Provided that the script works on one list, all lists will be right without needing manual control, as MIX does not allow constraints which are mathematically not applicable to the dataset. In other words, if the specified sequence is not possible, no list is generated, making randomization with MIX fail-proof.\\
	
	Pseudorandomization tasks with MIX are also more reliable than manual randomization as well as more efficient, as the script has to be written only once and may be re-used as many times as necessary whenever any changes in the design or the constraints are made or any mistake in the composition of the lists is found.\\
	
	After generating the 8x8 randomized lists, I added the practice trials with following script in Python 3.
	
	\lstset{language=Python}
	\begin{lstlisting}
	# specifies the list of lists which have to be processed
	import os
	cwd="myfolder"
	filelist=os.listdir("myfolder_lists")
	
	# opens each one the 64 lists and reads its content one row at a time
	for path in filelist:
	mypath="".join(("test/input/",path))
	f=open(mypath, "r")
	contents=f.readlines()
	
	# adds the specified content (the content of each line) in the second, third, fourth and fith line, respectively
	contents.insert(1, "[content of practice trial 1, tab separated]\n")
	contents.insert(2, "[content of practice trial 2, tab separated]\n")
	contents.insert(3, "[content of practice trial 3, tab separated]\n")
	contents.insert(4, "[content of practice trial 3, tab separated]\n")
	f.close()
	
	# integrates the new lines into the rest of the list
	mypath="".join(("test/output/",path))
	ff=open(mypath, "w+")
	contents = "".join(contents)
	
	# writes and closes the files
	ff.write(contents)
	ff.close()
	\end{lstlisting}
	
	Both scripts run on Windows systems. The Python script may work on Mac, too, but may need minor adjustments; the MIX script cannot work on systems other than Windows, as the MIX software has currently only been issued for Windows OSs.\\
	
	\subsection{Participants}
	The participants will be 64 right-handed young adults (32 women) between 18 and 30 with normal or corrected to normal vision and normal hearing who have not acquired a second language before age 6;0.\\
	
	Participants are recruited within the student's community only, in order to implicitly control for socio-economic status and literacy. Up until time of writing, they were recruited using the University's mailing list for students and the LingEx database provided by Leibniz Zentrum für Allgemeine Sprachwissenschaft (ZAS)\footnote{https://lingex.zas.gwz-berlin.de/public/}.\\
	
	All participants received 8,50 euro for taking part to the study. Before participating, they received a participant's information sheet and signed a consent form for the storage and use of their data. They also filled in a participant questionnaire in which they had to declare that they comply with the participation requirements - among others that their vision was normal or corrected-to-normal, that they did not learn a second language before the age of 6;0. Each participant also declared his/her sex choosing between \textit{männlich} ('male') and \textit{weiblich} ('female').\\
	
	During the experiment, I kept a log containing information about any time a participant requested a pause or an unplanned event occurred. After the experiment, each participant received a post experiment form in which s/he was asked to write down what they thought it was the purpose of the study, whether they had noticed any pattern, and, finally, whether they had developed and employed any strategy while performing the experimental tasks.\\
	
	In compliance with the lab's data protection rules, the participant questionnaire, the experiment log and the post-experiment form were anonymous and coded by the participant's ID only. The consent form, which contained the participant's information, was stored separately in the moment the participant left the lab, so that it is not possible to trace back any data or experiment information to a specific participant.\\
	
	\subsection{Stimuli}
	An SR Research EyeLink 1000 eye-tracker will record the fixation patterns of the participants whilen the visual stimuli are presented on a monitor with a resolution of 1920x1080 pixels. The stimuli materials consist of a short video of a woman's face, a set of 16 item sentences in German (+28 fillers) and a corresponding set of 16 item scenes (+28 fillers). Each trial sentence is followed by a correspondent verification sentence (16 items + 28 fillers). The trial lists are pseudo-randomized using the program MIX by \cite{cada}. The item trial sentences are non-canonical OVS and are constructed as follows:\\
	
	\ex. NP1.m.acc.+ verb of action + positive adverb + NP2.nom\\
	
	%\begin{center}
	%	\begin{tabular}{ l | c | r }
		%	\hline
			% & items & fillers \\ \hline
			%trial sentence & 16 & 28 \\ \hline
			%verification sentence & 16 & 28 \\ \hline
			%visual scenes & 16 & 28 \\ \hline
			%prime face video && 2\\ \hline
		%\end{tabular}
%	\end{center}
	
	%The emotionally valenced video of the woman's facial expression should prime a positive or negative emotion in the viewer-listener. During video presentation, which lasts 5500 ms in total, the woman's expression changes from neutral to happy or from neutral to sad.

	As German masculine accusative articles are unequivocally marked as accusative, presenting a masculine accusative DP at sentence begin unequivocally marks that first constituent as the grammatical object and thematic patient of the sentence. This sentence order prepares the listener-viewer to expect, and, if possible, anticipate, the grammatical subject and agent of the sentence. The item visual scene portray the agent and a distractor (but not the patient), and each character pair features a happy character and a sad character. During online comprehension, both figures may be good candidates for the agent role up until adverb presentation. The adverb will describe the internal state of the agent, thus providing a social cue for the participant to unambiguously identify the correct agent character.\\
	
	%STIMULI CHANGES COMPARED TO MUEN
	Both the sentences and the image material are adapted from \cite{muen}, experiment 3. In the main task, the trial sentences are used without changes while the visual scenes have been modified in order to further underline the facial expression of the character according to its internal state as described in the sentence; additionally, in the experimental scenes the action and the patient were removed from the picture to exclude the possibility of confounds due to the effect of action depiction. The verification tasks have also been adapted. The verification sentences are changed to allow a yes/no answer to the task question "Is the meaning of the task sentence identical to the meaning of the scene sentence?". The face verification task is new to the current design.\\
	
	
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{design_new.png}
		\caption{Schematic of the trial's design}
		\label{fig:design_new}
	\end{figure}
	
	The participants are told that the aim of the experiment is to test how adults perceive child-directed speech. In the experiment instructions, they read that they will see the picture of a mother describing cartoon-scenes to her child and they will be asked to take a decision task about the content of the utterance.\\
	
	Figure \ref{fig:design_new} schematically shows the trial's design. Trials will start with the video of a woman's face changing expression from neutral to happy or from neutral to sad - the prime face video. I assume this video to prime a positive or negative emotion in the viewer-listener. A cartoon-like scene will follow. The figures in the scene will have a negative or positive facial expression. A woman's voice will then describe the scene with a sentence. All trial sentences contain a positive or a negative adverb. After that, a picture from the prime face video will appear. This picture is taken from the moment of the video where the emotion peaks and will be consistent or not consistent with the video presented at the begin of the trial. The participant will decide with a yes/no button whether the picture he has seen has the same emotional valence as the video presented in the same trial. Afterwards, s/he will hear a verification sentence and decide (using the same yes/no button) whether the content of the verification sentence us is the same than the content of the trial sentence.\\
	
		\begin{figure}[h!]
		\includegraphics[width=\linewidth]{design_new_final.png}
		\caption{Schematic of the trial's design with trial segments}
		\label{fig:design_new_final}
	\end{figure}
	
	Figure \ref{fig:design_new_final} further divides a trial in smaller segments. In the main task, I expect priming to occur. The fixations are tracked here during presentation of the trial sentence - specifically, in the adverb window. In the remaining two segments of the trial, two control tasks are performed. A first one verifies whether the participant has understood and retained the valence of the prime face and is completed by pressing a yes/no button. The second control task verifies whether the participant has understood the meaning of the sentence, has assigned the thematic roles correctly and has retained this information throughout the trial. This task is also completed by pressing a yes/no button. The main task is taken from \cite{muen} without changes, thus allowing comparisons of the results. The emotion verifcation task is new to the current design. The meaning verification task is similar to the one use used by \cite{muen}, but the type of question differs. In the previous design, participants had to state "who performed an action on whom", in the current design they have to provide a yes/no answer about the sentence meaning. This way, it should be easier to record and compare reaction times.\\
	
	After receiving the experiment instructions and after four practice trials, all trials will follow in two blocks. Block one will consist of trials 1 to 22, then the participant will be asked if s/he wishes to take a pause, after which the remaining 22 trials will follow.
	
	\section{Hypothesis}
	As \cite{muen} did in younger adults, I expect to find a difference in the time course of thematic role assignment depending on the (in-)congruence of the primed emotion. In the congruent condition (the prime video has the same emotional valence as the adverb in the trial sentence), I expect the participants to be able to assign thematic roles quicker than in the incongruent condition (the prime video has not the same emotional valence as the adverb in the trial sentence). This would translate into earlier fixations toward the agent of the trial sentence portrayed in the scene in the congruent condition. I expect these anticipatory fixations to appear as early as in the adverb region. This region is the one where participant should be able to choose the right one out of two possible referents if emotional priming is integrated in sentence processing.\\
	
	It is possible that no differences between congruent and non-congruent condition are found. This may be linked to the high task requirements, as the study design requires participants to retain different pieces of information in working memory and to use relevant information quickly in active tasks. A follow up experiment may also take participant's working knowledge into account and verify to which extent it may be a factor in similar tasks.\\
	
	I also expect women to be quicker then men in identifying the agent of the sentence using emotions as a cue, as women have been found to outperform men in tasks where they are asked to infer the internal state of a others and to make predictions based on these inferences \citep{cahi,aden,baro}. If women outperform men in identifying emotions, it is possible that emotional cues are also more salient to them then to men and that priming effects grounded on emotions may be stronger for women than for men.\\
	
	It is possible that no differences between the fixation behavior of women and men would be found. If so, it may mean that men and women do not differ in their ability to identify emotional cues and to use them to make predictions.\\
	
	In the control tasks, I expect participants to be able to recognize correctly whether the verification picture and the prime video did or did not portray the same emotion in most trials and to be able to state correctly whether the meaning of the trial sentence and the one of the verification sentence are the same. Failing these control task on individual trials, I will assume that the participant did not pay attention on individual trials. Failing the control task on most trials, I will assume that the participant did not perform or understand the task. Data from invalid trials may be excluded from further analyses.\\
	
	As stated for the main task, it is again possible that the control tasks are failed due to the high task requirements in connection with the main task. If these tasks are failed by a high proportion of participants, the experiment may be repeated including working memory as a factor, as mentioned earlier in this section.\\
		
	\section{Analysis}
	\subsection{Data collection}
	At the time of writing this thesis, 17 of the total 64 participants had been tested (12 women). One (male) participant did not perform the task correctly, as he tended to fixate a point in the middle of the screen only, and his data was excluded from further analysis. Due to the few data points evaluated so far, the results analysed and discussed in the following sections have a rather descriptive character and should be confirmed (or updated) by the results of the study in full length.\\
	
	The disproportion of women over men in the subsample tested until the time of writing this thesis also does not allow for a gender comparison, so that the potential impact of sex in the processing of visually and socially situated language will not be considered in the analysis of the first results. Also, due to the number of participants tested so far, the position of the yes/no button is not counterbalanced for this portion of the tests (the yes button was on the right hand side for all participants; as stated in Section (0), key counterbalance is planned for the second half of the participants).\\
	
	\subsection{Data processing}
	Using the RS Research Data Viewer, I drew the area of interest of each of the trial item scenes and defined them as area of the agent character or area of the distractor character, respectively. This way, every item scene was defined for three areas: the distractor's, the agent's, and a neutral area corresponding to the background. The areas of interest were overlaid onto the trial recordings. Based on this information, the Data Viewer generated a table where all fixations where categorized for area. All fixations to the neutral background were deleted, as they are not relevant to the study.\\
	
	The time window between scene preview time onset and NP2 offset was divided in 20-ms-time windows. The fixations to agent and distractor were referred to them in a table which coded whether the agent (or the distractor, respectively) was fixated in a specific 20-ms-time window.\\
	
	\subsection{Data analysis}
	\subsubsection{Main task}
	\paragraph{Time course graph}
	Based on the table of the fixations to the agent or distractor by time, a time course graph \ref{fig:time_course_graph} was generated. The time course graph depicts the log ratio of fixations to the target over the distractor on the y-axis and time in 20-ms-windows on the x-axis. By calculating the average time of NP1 onset, verb onset, adverb onset and NP2 onset, I then marked the differnt time regions on the graph.\\
	
	\subparagraph{Results}
	A visual inspection of the graph shows that the lines virtually overlap around zero in the NP1 and verb regions, suggesting no agent-distractor preference in those regions. In the adverb region, the lines the looks to the agent in the incongruous condition grow; looks to the agent finally grow in both conditions in the NP2 region. It is expected that participants have no strong preferences in the NP1 and verb region, as they had not been yet exposed to any disambiguating cue; as was the increase in the looks to the agent over the distractor in the NP2 region, because NP2 is the region where the agent is named.\\
	
	The region relevant to my study is, however, the adverb region. This is the earliest region where participants could use and (mis)match the emotional information. The results obtained in the adverb region are unexpected. As stated in the hypothesis, I expected anticipatory fixations to the agent to appear as early as in the adverb region, as this is the region where the (in)congruence of the emotional cues may be verified. These anticipatory looks were expected in the congruent condition, as this is the condition were the primed emotion should facilitate an earlier identification of the emotionally congruent agent. Unexpectedly, in the adverb region participants tended to look at the agent region more in the incongruent condition (when the positive sentence adverb was primed by a positive face) than in the congruent condition (when the positive sentence adverb was presented after a negative face).\\
	
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{time_course_graph_vorlaeufig.png}
		\caption{Graph of the time course of the fixations to agent and distractor from NP1 onset to NP2 offset. The x-axis reports time in milliseconds and the y-axis the log ratio of the number of fixations to the agent over the distractor. The labels NP1, verb, adverb and NP2 indicate the different sentence regions.}
		\label{fig:time_course_graph}
	\end{figure}
	\subparagraph{Summary and discussion}
	A visual inspection of Figure \ref{fig:time_course_graph} indicated that participants preferred to look at the agent over the distractor in the adverb region, and that this preference was stronger in the incongruent that in the congruent condition. This result is unexpected, as I was expecting  emotional priming to facilitate earlier anticipatory looks in the congruent condition (positive face, positive adverb) compared to the non-primed, incongruent condition (negative face, positive adverb). The result is also not consistent with \cite{muen}, who found that young adults preferred the agent over the distractor in the congruent condition.\\
	
	The graph suggests that participants were more sensitive to semantic mismatch than to semantic match. Mismatch effects are found in diverse domains of linguistic cognition and correlate to electrophysiological responses - like the N400 effect for semantic mismatch \citep{frie} or the MMN for phonetic mismatch \citep{naat}. Both in case of the N400 effect and in case of the MMN, an EEG component signalizes a processing pattern to cope with unexpected semantic (or phonetic, respectively) material after having been exposed to a mismatching prime.\\
	
	On the other hand, \cite{muen} did find facilitatory effects of the congruent emotion in her study, and the design of the main task were not structurally changed. Nevertheless, the visual stimuli used in the main task have been modified in the current design in order to maximize the positive or negative facial expressions. More marked facial expression may have been the reason why emotions were easier to identify in the current study, and, subsequently, were used as a cue in sentence processing. Taking into account the negativity bias, it is possible that the now more accessible emotions conveyed through the facial expressions of the scene characters have led the participants not to a preference for mismatching emotions, but for negative emotions, and that this effect did not come to light in \cite{muen} because the depicted emotions were less salient in her design.\\
	
	Additionally, the some of visual scenes presented in \cite{muen} also contained a reference to an action and a patient. The effect of action depiction may have have accounted for most of the variation.---------------------------------------
	
	\paragraph{Bar graph}
	A visual inspection of the graph in figure \ref{fig:bar_graph_ag_dis} confirms that, in the adverb region, participants preferred to look at the agent than at the distractor.
	
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{bar_graph_mean_log_ratios_ag_dis_adverb.png}
		\caption{Bar graph on mean log ratios of looks toward the agent over the distractor for the adverb region.}
		\label{fig:bar_graph_ag_dis}
	\end{figure}
	\subparagraph{Discussion}
	
	\paragraph{ANOVA by subject and by item}
	Using inferential statistics, I verify whether the results visually appreciated in the descriptive analysis are confirmed after filtering out variation present in data and not caused by the experimental conditions. I consider the impact of within-subject and within-item variation. In spite of careful selection of both participants and items, it is possible that a specific participant has in general a different visual inspection pattern than another; as well as a specific item may be more salient than another one. With an analysis of variance (ANOVA), I will evaluate whether the results obtained in the main task are statistically significant.\\
	
	A repeated measure ANOVA by subject on mean log ratios of looks to the agent over the distractor for the adverb region was performed; its results are reported in table \ref{fig:anova_subject}. It revealed no significant effect of prime face valence (F(1) = --------------------------------------, p -----.005).\\
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{Platzhalter.png}
		\caption{Results of the ANOVA by subject.}
		\label{fig:anova_subject}
	\end{figure}

	A repeated measure ANOVA by subject on mean log ratios of looks to the agent over the distractor for the adverb region (the results of which are reported in table \ref{fig:anova_item}) could also find no significant effect (F(1) = --------------------, p ----------.005).\\
	\begin{figure}[h!]
		\includegraphics[width=\linewidth]{Platzhalter.png}
		\caption{Results of the ANOVA by item.}
		\label{fig:anova_item}
	\end{figure}
	\subparagraph{Summary and discussion}
	The results of the ANOVAs indicate that the results obtained in the main task are not statistically significant. This may be due to the ---------------------------------
	
	\subsection{Verification tasks}
	\subsubsection{Data processing}
	For the verification tasks, reaction times (RTs) and accuracy were evaluated. Reaction times for each trial, subject and verification task were exported in milliseconds from the SR Research Software. The RTs reflect how many milliseconds after onset of the respective stimulus any response key (yes/no button) was hit. The accuracy data indicate whether the answer given by a subject for a specific trial and a specific task was correct.\\
	\subsubsection{Meaning verification task}
	In the meaning verification task, I test whether the participants have understood the trial sentence and are able to correctly answer the question: "Are the meaning of the trial sentence and the meaning of the verification sentence identical?".
	The reaction times were aggregated by item and performed a t-test on those means. The t-test did not reveal any difference between the primed and non-primed condition. The difference was still not significant after excluding all wrong answers.\\
	%check if true (aggregate by item usw.)
	
	\subparagraph{Summary and discussion}
	\subsubsection{Emotion verification task}
	In the meaning verification task, I test whether the participants have processed the emotion of the prime video and are able to correctly answer the question: "Are the prime video face and the face in the verification picture identical?".
	The reaction times were aggregated by item and performed a t-test on those means. The t-test did not reveal any difference between the primed and non-primed condition.  The difference was still not significant after excluding all wrong answers.\\
	%check if true (aggregate by item usw.) 
	\subparagraph{Summary and discussion}
	\section{Discussion}
	A descriptive representation of the fixations as a bar graph (figure \ref{fig:bar_graph_ag_dis}) revealed that participants preferred to look at the agent over the distractor in the adverb region. This tendency was found to be stronger in the non-primed condition compared to the primed condition - as visualized in the time course graph (figure \ref{fig:time_course_graph}) - which was unexpected. However, the difference between the congruent and incongruent condition was not significant, as confirmed by the inferential statistic (figures \ref{fig:anova_subject} and \ref{fig:anova_item}).\\
	
	It is important to remark again that the study has not been conducted to its full extent yet, therefore the data presented in this thesis has a rather descriptive character. If the current results are confirmed by the final result of the study, this may mean that visually presented emotional primes influence sentence processing in a different way than expected. Participants looked at the agent more in the incongruent condition (in the condition in which a negative prime was followed by a positive adverb) than in the congruent condition (the condition in which a positive prime was followed by a positive adverb). In the visual world paradigm, priming usually facilitates anticipatory looks to -------------------------
	
	\section{Outlook}
	A comparison of different age groups like in \cite{muen} may reveal how
	
	
	\section{Summary}

	\bibliography{emotions_visualworld_bib}

	\bibliographystyle{apacite}

\end{document}
